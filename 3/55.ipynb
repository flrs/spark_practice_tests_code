{"cells": [{"cell_type": "markdown", "source": ["# Test 3, Question 55\n> **Hint:** In Databricks, import code for all questions via this URL:\n> \n> https://github.com/flrs/spark_practice_tests_code/raw/main/spark_practice_tests_code.dbc"], "metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "87a4339f-cc26-4446-83b0-5fd419c20c70"}}}, {"cell_type": "code", "source": ["throughputRates = [0.237, 0.230, 0.2389, 0.594, 0.543]"], "metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "979b7cd4-f9a7-46f5-9def-4c35b4c6b587"}}, "outputs": [{"output_type": "display_data", "metadata": {"application/vnd.databricks.v1+output": {"datasetInfos": [], "data": "<div class=\"ansiout\"></div>", "removedWidgets": [], "addedWidgets": {}, "metadata": {}, "type": "html", "arguments": {}}}, "data": {"text/html": ["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}], "execution_count": 0}, {"cell_type": "markdown", "source": ["## Answer 1 (incorrect)"], "metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "9e7b8a51-bd8b-45ce-aed6-488cc351332a"}}}, {"cell_type": "code", "source": ["from pyspark.sql.types import FloatType\n\nspark.createDataFrame((throughputRates), FloatType).show()"], "metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "14f9adb3-dc1d-4e18-8cfa-4fddecdfdfcd"}}, "outputs": [{"output_type": "display_data", "metadata": {"application/vnd.databricks.v1+output": {"datasetInfos": [], "data": "<div class=\"ansiout\"></div>", "removedWidgets": [], "addedWidgets": {}, "metadata": {}, "type": "html", "arguments": {}}}, "data": {"text/html": ["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}, {"output_type": "display_data", "metadata": {"application/vnd.databricks.v1+output": {"data": "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">TypeError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3659936412987713&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-green-fg\">from</span> pyspark<span class=\"ansi-blue-fg\">.</span>sql<span class=\"ansi-blue-fg\">.</span>types <span class=\"ansi-green-fg\">import</span> FloatType\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> \n<span class=\"ansi-green-fg\">----&gt; 3</span><span class=\"ansi-red-fg\"> </span>spark<span class=\"ansi-blue-fg\">.</span>createDataFrame<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">(</span>throughputRates<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> FloatType<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>show<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">createDataFrame</span><span class=\"ansi-blue-fg\">(self, data, schema, samplingRatio, verifySchema)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    720</span>             return super(SparkSession, self).createDataFrame(\n<span class=\"ansi-green-intense-fg ansi-bold\">    721</span>                 data, schema, samplingRatio, verifySchema)\n<span class=\"ansi-green-fg\">--&gt; 722</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_create_dataframe<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">,</span> samplingRatio<span class=\"ansi-blue-fg\">,</span> verifySchema<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    723</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    724</span>     <span class=\"ansi-green-fg\">def</span> _create_dataframe<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> data<span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">,</span> samplingRatio<span class=\"ansi-blue-fg\">,</span> verifySchema<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">_create_dataframe</span><span class=\"ansi-blue-fg\">(self, data, schema, samplingRatio, verifySchema)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    752</span>                 rdd<span class=\"ansi-blue-fg\">,</span> schema <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_createFromRDD<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">.</span>map<span class=\"ansi-blue-fg\">(</span>prepare<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">,</span> samplingRatio<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    753</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 754</span><span class=\"ansi-red-fg\">                 </span>rdd<span class=\"ansi-blue-fg\">,</span> schema <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_createFromLocal<span class=\"ansi-blue-fg\">(</span>map<span class=\"ansi-blue-fg\">(</span>prepare<span class=\"ansi-blue-fg\">,</span> data<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    755</span>             jrdd <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_jvm<span class=\"ansi-blue-fg\">.</span>SerDeUtil<span class=\"ansi-blue-fg\">.</span>toJavaArray<span class=\"ansi-blue-fg\">(</span>rdd<span class=\"ansi-blue-fg\">.</span>_to_java_object_rdd<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    756</span>             jdf <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_jsparkSession<span class=\"ansi-blue-fg\">.</span>applySchemaToPythonRDD<span class=\"ansi-blue-fg\">(</span>jrdd<span class=\"ansi-blue-fg\">.</span>rdd<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">.</span>json<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">_createFromLocal</span><span class=\"ansi-blue-fg\">(self, data, schema)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    528</span>         write temp files<span class=\"ansi-blue-fg\">.</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    529</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-fg\">--&gt; 530</span><span class=\"ansi-red-fg\">         </span>data<span class=\"ansi-blue-fg\">,</span> schema <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_wrap_data_schema<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    531</span>         <span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_sc<span class=\"ansi-blue-fg\">.</span>parallelize<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> schema\n<span class=\"ansi-green-intense-fg ansi-bold\">    532</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">_wrap_data_schema</span><span class=\"ansi-blue-fg\">(self, data, schema)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    516</span>             schema <span class=\"ansi-blue-fg\">=</span> struct\n<span class=\"ansi-green-intense-fg ansi-bold\">    517</span>         <span class=\"ansi-green-fg\">elif</span> <span class=\"ansi-green-fg\">not</span> isinstance<span class=\"ansi-blue-fg\">(</span>schema<span class=\"ansi-blue-fg\">,</span> StructType<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 518</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">raise</span> TypeError<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;schema should be StructType or list or None, but got: %s&#34;</span> <span class=\"ansi-blue-fg\">%</span> schema<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    519</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    520</span>         <span class=\"ansi-red-fg\"># convert python objects to sql data</span>\n\n<span class=\"ansi-red-fg\">TypeError</span>: schema should be StructType or list or None, but got: &lt;class &#39;pyspark.sql.types.FloatType&#39;&gt;</div>", "errorSummary": "<span class=\"ansi-red-fg\">TypeError</span>: schema should be StructType or list or None, but got: &lt;class &#39;pyspark.sql.types.FloatType&#39;&gt;", "metadata": {}, "errorTraceType": "html", "type": "ipynbError", "arguments": {}}}, "data": {"text/html": ["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">TypeError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3659936412987713&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-green-fg\">from</span> pyspark<span class=\"ansi-blue-fg\">.</span>sql<span class=\"ansi-blue-fg\">.</span>types <span class=\"ansi-green-fg\">import</span> FloatType\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> \n<span class=\"ansi-green-fg\">----&gt; 3</span><span class=\"ansi-red-fg\"> </span>spark<span class=\"ansi-blue-fg\">.</span>createDataFrame<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">(</span>throughputRates<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> FloatType<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>show<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">createDataFrame</span><span class=\"ansi-blue-fg\">(self, data, schema, samplingRatio, verifySchema)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    720</span>             return super(SparkSession, self).createDataFrame(\n<span class=\"ansi-green-intense-fg ansi-bold\">    721</span>                 data, schema, samplingRatio, verifySchema)\n<span class=\"ansi-green-fg\">--&gt; 722</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_create_dataframe<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">,</span> samplingRatio<span class=\"ansi-blue-fg\">,</span> verifySchema<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    723</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    724</span>     <span class=\"ansi-green-fg\">def</span> _create_dataframe<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> data<span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">,</span> samplingRatio<span class=\"ansi-blue-fg\">,</span> verifySchema<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">_create_dataframe</span><span class=\"ansi-blue-fg\">(self, data, schema, samplingRatio, verifySchema)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    752</span>                 rdd<span class=\"ansi-blue-fg\">,</span> schema <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_createFromRDD<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">.</span>map<span class=\"ansi-blue-fg\">(</span>prepare<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">,</span> samplingRatio<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    753</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 754</span><span class=\"ansi-red-fg\">                 </span>rdd<span class=\"ansi-blue-fg\">,</span> schema <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_createFromLocal<span class=\"ansi-blue-fg\">(</span>map<span class=\"ansi-blue-fg\">(</span>prepare<span class=\"ansi-blue-fg\">,</span> data<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    755</span>             jrdd <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_jvm<span class=\"ansi-blue-fg\">.</span>SerDeUtil<span class=\"ansi-blue-fg\">.</span>toJavaArray<span class=\"ansi-blue-fg\">(</span>rdd<span class=\"ansi-blue-fg\">.</span>_to_java_object_rdd<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    756</span>             jdf <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_jsparkSession<span class=\"ansi-blue-fg\">.</span>applySchemaToPythonRDD<span class=\"ansi-blue-fg\">(</span>jrdd<span class=\"ansi-blue-fg\">.</span>rdd<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">.</span>json<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">_createFromLocal</span><span class=\"ansi-blue-fg\">(self, data, schema)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    528</span>         write temp files<span class=\"ansi-blue-fg\">.</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    529</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-fg\">--&gt; 530</span><span class=\"ansi-red-fg\">         </span>data<span class=\"ansi-blue-fg\">,</span> schema <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_wrap_data_schema<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    531</span>         <span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_sc<span class=\"ansi-blue-fg\">.</span>parallelize<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> schema\n<span class=\"ansi-green-intense-fg ansi-bold\">    532</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">_wrap_data_schema</span><span class=\"ansi-blue-fg\">(self, data, schema)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    516</span>             schema <span class=\"ansi-blue-fg\">=</span> struct\n<span class=\"ansi-green-intense-fg ansi-bold\">    517</span>         <span class=\"ansi-green-fg\">elif</span> <span class=\"ansi-green-fg\">not</span> isinstance<span class=\"ansi-blue-fg\">(</span>schema<span class=\"ansi-blue-fg\">,</span> StructType<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 518</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">raise</span> TypeError<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;schema should be StructType or list or None, but got: %s&#34;</span> <span class=\"ansi-blue-fg\">%</span> schema<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    519</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    520</span>         <span class=\"ansi-red-fg\"># convert python objects to sql data</span>\n\n<span class=\"ansi-red-fg\">TypeError</span>: schema should be StructType or list or None, but got: &lt;class &#39;pyspark.sql.types.FloatType&#39;&gt;</div>"]}}], "execution_count": 0}, {"cell_type": "markdown", "source": ["## Answer 2 (incorrect)"], "metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "8fef6132-53bf-4c40-b876-e17972c28fe8"}}}, {"cell_type": "code", "source": ["from pyspark.sql.types import FloatType\n\nspark.createDataFrame(throughputRates, FloatType).show()"], "metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "4a1dfb7c-aaf8-4c46-89c0-7367cb77a413"}}, "outputs": [{"output_type": "display_data", "metadata": {"application/vnd.databricks.v1+output": {"datasetInfos": [], "data": "<div class=\"ansiout\"></div>", "removedWidgets": [], "addedWidgets": {}, "metadata": {}, "type": "html", "arguments": {}}}, "data": {"text/html": ["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}, {"output_type": "display_data", "metadata": {"application/vnd.databricks.v1+output": {"data": "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">TypeError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3659936412987715&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-green-fg\">from</span> pyspark<span class=\"ansi-blue-fg\">.</span>sql<span class=\"ansi-blue-fg\">.</span>types <span class=\"ansi-green-fg\">import</span> FloatType\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> \n<span class=\"ansi-green-fg\">----&gt; 3</span><span class=\"ansi-red-fg\"> </span>spark<span class=\"ansi-blue-fg\">.</span>createDataFrame<span class=\"ansi-blue-fg\">(</span>throughputRates<span class=\"ansi-blue-fg\">,</span> FloatType<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>show<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">createDataFrame</span><span class=\"ansi-blue-fg\">(self, data, schema, samplingRatio, verifySchema)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    720</span>             return super(SparkSession, self).createDataFrame(\n<span class=\"ansi-green-intense-fg ansi-bold\">    721</span>                 data, schema, samplingRatio, verifySchema)\n<span class=\"ansi-green-fg\">--&gt; 722</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_create_dataframe<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">,</span> samplingRatio<span class=\"ansi-blue-fg\">,</span> verifySchema<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    723</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    724</span>     <span class=\"ansi-green-fg\">def</span> _create_dataframe<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> data<span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">,</span> samplingRatio<span class=\"ansi-blue-fg\">,</span> verifySchema<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">_create_dataframe</span><span class=\"ansi-blue-fg\">(self, data, schema, samplingRatio, verifySchema)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    752</span>                 rdd<span class=\"ansi-blue-fg\">,</span> schema <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_createFromRDD<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">.</span>map<span class=\"ansi-blue-fg\">(</span>prepare<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">,</span> samplingRatio<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    753</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 754</span><span class=\"ansi-red-fg\">                 </span>rdd<span class=\"ansi-blue-fg\">,</span> schema <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_createFromLocal<span class=\"ansi-blue-fg\">(</span>map<span class=\"ansi-blue-fg\">(</span>prepare<span class=\"ansi-blue-fg\">,</span> data<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    755</span>             jrdd <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_jvm<span class=\"ansi-blue-fg\">.</span>SerDeUtil<span class=\"ansi-blue-fg\">.</span>toJavaArray<span class=\"ansi-blue-fg\">(</span>rdd<span class=\"ansi-blue-fg\">.</span>_to_java_object_rdd<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    756</span>             jdf <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_jsparkSession<span class=\"ansi-blue-fg\">.</span>applySchemaToPythonRDD<span class=\"ansi-blue-fg\">(</span>jrdd<span class=\"ansi-blue-fg\">.</span>rdd<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">.</span>json<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">_createFromLocal</span><span class=\"ansi-blue-fg\">(self, data, schema)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    528</span>         write temp files<span class=\"ansi-blue-fg\">.</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    529</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-fg\">--&gt; 530</span><span class=\"ansi-red-fg\">         </span>data<span class=\"ansi-blue-fg\">,</span> schema <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_wrap_data_schema<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    531</span>         <span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_sc<span class=\"ansi-blue-fg\">.</span>parallelize<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> schema\n<span class=\"ansi-green-intense-fg ansi-bold\">    532</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">_wrap_data_schema</span><span class=\"ansi-blue-fg\">(self, data, schema)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    516</span>             schema <span class=\"ansi-blue-fg\">=</span> struct\n<span class=\"ansi-green-intense-fg ansi-bold\">    517</span>         <span class=\"ansi-green-fg\">elif</span> <span class=\"ansi-green-fg\">not</span> isinstance<span class=\"ansi-blue-fg\">(</span>schema<span class=\"ansi-blue-fg\">,</span> StructType<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 518</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">raise</span> TypeError<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;schema should be StructType or list or None, but got: %s&#34;</span> <span class=\"ansi-blue-fg\">%</span> schema<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    519</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    520</span>         <span class=\"ansi-red-fg\"># convert python objects to sql data</span>\n\n<span class=\"ansi-red-fg\">TypeError</span>: schema should be StructType or list or None, but got: &lt;class &#39;pyspark.sql.types.FloatType&#39;&gt;</div>", "errorSummary": "<span class=\"ansi-red-fg\">TypeError</span>: schema should be StructType or list or None, but got: &lt;class &#39;pyspark.sql.types.FloatType&#39;&gt;", "metadata": {}, "errorTraceType": "html", "type": "ipynbError", "arguments": {}}}, "data": {"text/html": ["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">TypeError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3659936412987715&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-green-fg\">from</span> pyspark<span class=\"ansi-blue-fg\">.</span>sql<span class=\"ansi-blue-fg\">.</span>types <span class=\"ansi-green-fg\">import</span> FloatType\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> \n<span class=\"ansi-green-fg\">----&gt; 3</span><span class=\"ansi-red-fg\"> </span>spark<span class=\"ansi-blue-fg\">.</span>createDataFrame<span class=\"ansi-blue-fg\">(</span>throughputRates<span class=\"ansi-blue-fg\">,</span> FloatType<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>show<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">createDataFrame</span><span class=\"ansi-blue-fg\">(self, data, schema, samplingRatio, verifySchema)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    720</span>             return super(SparkSession, self).createDataFrame(\n<span class=\"ansi-green-intense-fg ansi-bold\">    721</span>                 data, schema, samplingRatio, verifySchema)\n<span class=\"ansi-green-fg\">--&gt; 722</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_create_dataframe<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">,</span> samplingRatio<span class=\"ansi-blue-fg\">,</span> verifySchema<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    723</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    724</span>     <span class=\"ansi-green-fg\">def</span> _create_dataframe<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> data<span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">,</span> samplingRatio<span class=\"ansi-blue-fg\">,</span> verifySchema<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">_create_dataframe</span><span class=\"ansi-blue-fg\">(self, data, schema, samplingRatio, verifySchema)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    752</span>                 rdd<span class=\"ansi-blue-fg\">,</span> schema <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_createFromRDD<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">.</span>map<span class=\"ansi-blue-fg\">(</span>prepare<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">,</span> samplingRatio<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    753</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 754</span><span class=\"ansi-red-fg\">                 </span>rdd<span class=\"ansi-blue-fg\">,</span> schema <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_createFromLocal<span class=\"ansi-blue-fg\">(</span>map<span class=\"ansi-blue-fg\">(</span>prepare<span class=\"ansi-blue-fg\">,</span> data<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    755</span>             jrdd <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_jvm<span class=\"ansi-blue-fg\">.</span>SerDeUtil<span class=\"ansi-blue-fg\">.</span>toJavaArray<span class=\"ansi-blue-fg\">(</span>rdd<span class=\"ansi-blue-fg\">.</span>_to_java_object_rdd<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    756</span>             jdf <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_jsparkSession<span class=\"ansi-blue-fg\">.</span>applySchemaToPythonRDD<span class=\"ansi-blue-fg\">(</span>jrdd<span class=\"ansi-blue-fg\">.</span>rdd<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">.</span>json<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">_createFromLocal</span><span class=\"ansi-blue-fg\">(self, data, schema)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    528</span>         write temp files<span class=\"ansi-blue-fg\">.</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    529</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-fg\">--&gt; 530</span><span class=\"ansi-red-fg\">         </span>data<span class=\"ansi-blue-fg\">,</span> schema <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_wrap_data_schema<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    531</span>         <span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_sc<span class=\"ansi-blue-fg\">.</span>parallelize<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> schema\n<span class=\"ansi-green-intense-fg ansi-bold\">    532</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">_wrap_data_schema</span><span class=\"ansi-blue-fg\">(self, data, schema)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    516</span>             schema <span class=\"ansi-blue-fg\">=</span> struct\n<span class=\"ansi-green-intense-fg ansi-bold\">    517</span>         <span class=\"ansi-green-fg\">elif</span> <span class=\"ansi-green-fg\">not</span> isinstance<span class=\"ansi-blue-fg\">(</span>schema<span class=\"ansi-blue-fg\">,</span> StructType<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 518</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">raise</span> TypeError<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;schema should be StructType or list or None, but got: %s&#34;</span> <span class=\"ansi-blue-fg\">%</span> schema<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    519</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    520</span>         <span class=\"ansi-red-fg\"># convert python objects to sql data</span>\n\n<span class=\"ansi-red-fg\">TypeError</span>: schema should be StructType or list or None, but got: &lt;class &#39;pyspark.sql.types.FloatType&#39;&gt;</div>"]}}], "execution_count": 0}, {"cell_type": "markdown", "source": ["## Answer 3 (incorrect)"], "metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "9edca3fe-7135-4cbe-a61a-a5dbd2d4c733"}}}, {"cell_type": "code", "source": ["from pyspark.sql.types import FloatType\n\nspark.DataFrame(throughputRates, FloatType).show()"], "metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "6c3f712f-0536-4ce8-ad81-b36c5ec71945"}}, "outputs": [{"output_type": "display_data", "metadata": {"application/vnd.databricks.v1+output": {"datasetInfos": [], "data": "<div class=\"ansiout\"></div>", "removedWidgets": [], "addedWidgets": {}, "metadata": {}, "type": "html", "arguments": {}}}, "data": {"text/html": ["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}, {"output_type": "display_data", "metadata": {"application/vnd.databricks.v1+output": {"data": "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">AttributeError</span>                            Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3659936412987717&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-green-fg\">from</span> pyspark<span class=\"ansi-blue-fg\">.</span>sql<span class=\"ansi-blue-fg\">.</span>types <span class=\"ansi-green-fg\">import</span> FloatType\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> \n<span class=\"ansi-green-fg\">----&gt; 3</span><span class=\"ansi-red-fg\"> </span>spark<span class=\"ansi-blue-fg\">.</span>DataFrame<span class=\"ansi-blue-fg\">(</span>throughputRates<span class=\"ansi-blue-fg\">,</span> FloatType<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>show<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-red-fg\">AttributeError</span>: &#39;SparkSession&#39; object has no attribute &#39;DataFrame&#39;</div>", "errorSummary": "<span class=\"ansi-red-fg\">AttributeError</span>: &#39;SparkSession&#39; object has no attribute &#39;DataFrame&#39;", "metadata": {}, "errorTraceType": "html", "type": "ipynbError", "arguments": {}}}, "data": {"text/html": ["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">AttributeError</span>                            Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3659936412987717&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-green-fg\">from</span> pyspark<span class=\"ansi-blue-fg\">.</span>sql<span class=\"ansi-blue-fg\">.</span>types <span class=\"ansi-green-fg\">import</span> FloatType\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> \n<span class=\"ansi-green-fg\">----&gt; 3</span><span class=\"ansi-red-fg\"> </span>spark<span class=\"ansi-blue-fg\">.</span>DataFrame<span class=\"ansi-blue-fg\">(</span>throughputRates<span class=\"ansi-blue-fg\">,</span> FloatType<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>show<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-red-fg\">AttributeError</span>: &#39;SparkSession&#39; object has no attribute &#39;DataFrame&#39;</div>"]}}], "execution_count": 0}, {"cell_type": "markdown", "source": ["## Answer 4 (incorrect)"], "metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "3da08153-8385-45d8-85f4-9d1e5156ec37"}}}, {"cell_type": "code", "source": ["spark.createDataFrame(throughputRates).show()"], "metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "741846ba-74a7-4878-9715-49e613b7b7e2"}}, "outputs": [{"output_type": "display_data", "metadata": {"application/vnd.databricks.v1+output": {"datasetInfos": [], "data": "<div class=\"ansiout\"></div>", "removedWidgets": [], "addedWidgets": {}, "metadata": {}, "type": "html", "arguments": {}}}, "data": {"text/html": ["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}, {"output_type": "display_data", "metadata": {"application/vnd.databricks.v1+output": {"data": "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">TypeError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3659936412987719&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span>spark<span class=\"ansi-blue-fg\">.</span>createDataFrame<span class=\"ansi-blue-fg\">(</span>throughputRates<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>show<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">createDataFrame</span><span class=\"ansi-blue-fg\">(self, data, schema, samplingRatio, verifySchema)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    720</span>             return super(SparkSession, self).createDataFrame(\n<span class=\"ansi-green-intense-fg ansi-bold\">    721</span>                 data, schema, samplingRatio, verifySchema)\n<span class=\"ansi-green-fg\">--&gt; 722</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_create_dataframe<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">,</span> samplingRatio<span class=\"ansi-blue-fg\">,</span> verifySchema<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    723</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    724</span>     <span class=\"ansi-green-fg\">def</span> _create_dataframe<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> data<span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">,</span> samplingRatio<span class=\"ansi-blue-fg\">,</span> verifySchema<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">_create_dataframe</span><span class=\"ansi-blue-fg\">(self, data, schema, samplingRatio, verifySchema)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    752</span>                 rdd<span class=\"ansi-blue-fg\">,</span> schema <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_createFromRDD<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">.</span>map<span class=\"ansi-blue-fg\">(</span>prepare<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">,</span> samplingRatio<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    753</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 754</span><span class=\"ansi-red-fg\">                 </span>rdd<span class=\"ansi-blue-fg\">,</span> schema <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_createFromLocal<span class=\"ansi-blue-fg\">(</span>map<span class=\"ansi-blue-fg\">(</span>prepare<span class=\"ansi-blue-fg\">,</span> data<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    755</span>             jrdd <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_jvm<span class=\"ansi-blue-fg\">.</span>SerDeUtil<span class=\"ansi-blue-fg\">.</span>toJavaArray<span class=\"ansi-blue-fg\">(</span>rdd<span class=\"ansi-blue-fg\">.</span>_to_java_object_rdd<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    756</span>             jdf <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_jsparkSession<span class=\"ansi-blue-fg\">.</span>applySchemaToPythonRDD<span class=\"ansi-blue-fg\">(</span>jrdd<span class=\"ansi-blue-fg\">.</span>rdd<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">.</span>json<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">_createFromLocal</span><span class=\"ansi-blue-fg\">(self, data, schema)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    528</span>         write temp files<span class=\"ansi-blue-fg\">.</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    529</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-fg\">--&gt; 530</span><span class=\"ansi-red-fg\">         </span>data<span class=\"ansi-blue-fg\">,</span> schema <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_wrap_data_schema<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    531</span>         <span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_sc<span class=\"ansi-blue-fg\">.</span>parallelize<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> schema\n<span class=\"ansi-green-intense-fg ansi-bold\">    532</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">_wrap_data_schema</span><span class=\"ansi-blue-fg\">(self, data, schema)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    507</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    508</span>         <span class=\"ansi-green-fg\">if</span> schema <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">None</span> <span class=\"ansi-green-fg\">or</span> isinstance<span class=\"ansi-blue-fg\">(</span>schema<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">(</span>list<span class=\"ansi-blue-fg\">,</span> tuple<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 509</span><span class=\"ansi-red-fg\">             </span>struct <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_inferSchemaFromList<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">,</span> names<span class=\"ansi-blue-fg\">=</span>schema<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    510</span>             converter <span class=\"ansi-blue-fg\">=</span> _create_converter<span class=\"ansi-blue-fg\">(</span>struct<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    511</span>             data <span class=\"ansi-blue-fg\">=</span> map<span class=\"ansi-blue-fg\">(</span>converter<span class=\"ansi-blue-fg\">,</span> data<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">_inferSchemaFromList</span><span class=\"ansi-blue-fg\">(self, data, names)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    438</span>         <span class=\"ansi-green-fg\">if</span> <span class=\"ansi-green-fg\">not</span> data<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    439</span>             <span class=\"ansi-green-fg\">raise</span> ValueError<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;can not infer schema from empty dataset&#34;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">--&gt; 440</span><span class=\"ansi-red-fg\">         </span>schema <span class=\"ansi-blue-fg\">=</span> reduce<span class=\"ansi-blue-fg\">(</span>_merge_type<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">(</span>_infer_schema<span class=\"ansi-blue-fg\">(</span>row<span class=\"ansi-blue-fg\">,</span> names<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">for</span> row <span class=\"ansi-green-fg\">in</span> data<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    441</span>         <span class=\"ansi-green-fg\">if</span> _has_nulltype<span class=\"ansi-blue-fg\">(</span>schema<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    442</span>             <span class=\"ansi-green-fg\">raise</span> ValueError<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;Some of types cannot be determined after inferring&#34;</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">&lt;genexpr&gt;</span><span class=\"ansi-blue-fg\">(.0)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    438</span>         <span class=\"ansi-green-fg\">if</span> <span class=\"ansi-green-fg\">not</span> data<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    439</span>             <span class=\"ansi-green-fg\">raise</span> ValueError<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;can not infer schema from empty dataset&#34;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">--&gt; 440</span><span class=\"ansi-red-fg\">         </span>schema <span class=\"ansi-blue-fg\">=</span> reduce<span class=\"ansi-blue-fg\">(</span>_merge_type<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">(</span>_infer_schema<span class=\"ansi-blue-fg\">(</span>row<span class=\"ansi-blue-fg\">,</span> names<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">for</span> row <span class=\"ansi-green-fg\">in</span> data<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    441</span>         <span class=\"ansi-green-fg\">if</span> _has_nulltype<span class=\"ansi-blue-fg\">(</span>schema<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    442</span>             <span class=\"ansi-green-fg\">raise</span> ValueError<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;Some of types cannot be determined after inferring&#34;</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/types.py</span> in <span class=\"ansi-cyan-fg\">_infer_schema</span><span class=\"ansi-blue-fg\">(row, names)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1063</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1064</span>     <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">-&gt; 1065</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">raise</span> TypeError<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;Can not infer schema for type: %s&#34;</span> <span class=\"ansi-blue-fg\">%</span> type<span class=\"ansi-blue-fg\">(</span>row<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1066</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1067</span>     fields <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">[</span><span class=\"ansi-blue-fg\">]</span>\n\n<span class=\"ansi-red-fg\">TypeError</span>: Can not infer schema for type: &lt;class &#39;float&#39;&gt;</div>", "errorSummary": "<span class=\"ansi-red-fg\">TypeError</span>: Can not infer schema for type: &lt;class &#39;float&#39;&gt;", "metadata": {}, "errorTraceType": "html", "type": "ipynbError", "arguments": {}}}, "data": {"text/html": ["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">TypeError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3659936412987719&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span>spark<span class=\"ansi-blue-fg\">.</span>createDataFrame<span class=\"ansi-blue-fg\">(</span>throughputRates<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>show<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">createDataFrame</span><span class=\"ansi-blue-fg\">(self, data, schema, samplingRatio, verifySchema)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    720</span>             return super(SparkSession, self).createDataFrame(\n<span class=\"ansi-green-intense-fg ansi-bold\">    721</span>                 data, schema, samplingRatio, verifySchema)\n<span class=\"ansi-green-fg\">--&gt; 722</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_create_dataframe<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">,</span> samplingRatio<span class=\"ansi-blue-fg\">,</span> verifySchema<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    723</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    724</span>     <span class=\"ansi-green-fg\">def</span> _create_dataframe<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> data<span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">,</span> samplingRatio<span class=\"ansi-blue-fg\">,</span> verifySchema<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">_create_dataframe</span><span class=\"ansi-blue-fg\">(self, data, schema, samplingRatio, verifySchema)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    752</span>                 rdd<span class=\"ansi-blue-fg\">,</span> schema <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_createFromRDD<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">.</span>map<span class=\"ansi-blue-fg\">(</span>prepare<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">,</span> samplingRatio<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    753</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 754</span><span class=\"ansi-red-fg\">                 </span>rdd<span class=\"ansi-blue-fg\">,</span> schema <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_createFromLocal<span class=\"ansi-blue-fg\">(</span>map<span class=\"ansi-blue-fg\">(</span>prepare<span class=\"ansi-blue-fg\">,</span> data<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    755</span>             jrdd <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_jvm<span class=\"ansi-blue-fg\">.</span>SerDeUtil<span class=\"ansi-blue-fg\">.</span>toJavaArray<span class=\"ansi-blue-fg\">(</span>rdd<span class=\"ansi-blue-fg\">.</span>_to_java_object_rdd<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    756</span>             jdf <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_jsparkSession<span class=\"ansi-blue-fg\">.</span>applySchemaToPythonRDD<span class=\"ansi-blue-fg\">(</span>jrdd<span class=\"ansi-blue-fg\">.</span>rdd<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">.</span>json<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">_createFromLocal</span><span class=\"ansi-blue-fg\">(self, data, schema)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    528</span>         write temp files<span class=\"ansi-blue-fg\">.</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    529</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-fg\">--&gt; 530</span><span class=\"ansi-red-fg\">         </span>data<span class=\"ansi-blue-fg\">,</span> schema <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_wrap_data_schema<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    531</span>         <span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_sc<span class=\"ansi-blue-fg\">.</span>parallelize<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> schema\n<span class=\"ansi-green-intense-fg ansi-bold\">    532</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">_wrap_data_schema</span><span class=\"ansi-blue-fg\">(self, data, schema)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    507</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    508</span>         <span class=\"ansi-green-fg\">if</span> schema <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">None</span> <span class=\"ansi-green-fg\">or</span> isinstance<span class=\"ansi-blue-fg\">(</span>schema<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">(</span>list<span class=\"ansi-blue-fg\">,</span> tuple<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 509</span><span class=\"ansi-red-fg\">             </span>struct <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_inferSchemaFromList<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">,</span> names<span class=\"ansi-blue-fg\">=</span>schema<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    510</span>             converter <span class=\"ansi-blue-fg\">=</span> _create_converter<span class=\"ansi-blue-fg\">(</span>struct<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    511</span>             data <span class=\"ansi-blue-fg\">=</span> map<span class=\"ansi-blue-fg\">(</span>converter<span class=\"ansi-blue-fg\">,</span> data<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">_inferSchemaFromList</span><span class=\"ansi-blue-fg\">(self, data, names)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    438</span>         <span class=\"ansi-green-fg\">if</span> <span class=\"ansi-green-fg\">not</span> data<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    439</span>             <span class=\"ansi-green-fg\">raise</span> ValueError<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;can not infer schema from empty dataset&#34;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">--&gt; 440</span><span class=\"ansi-red-fg\">         </span>schema <span class=\"ansi-blue-fg\">=</span> reduce<span class=\"ansi-blue-fg\">(</span>_merge_type<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">(</span>_infer_schema<span class=\"ansi-blue-fg\">(</span>row<span class=\"ansi-blue-fg\">,</span> names<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">for</span> row <span class=\"ansi-green-fg\">in</span> data<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    441</span>         <span class=\"ansi-green-fg\">if</span> _has_nulltype<span class=\"ansi-blue-fg\">(</span>schema<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    442</span>             <span class=\"ansi-green-fg\">raise</span> ValueError<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;Some of types cannot be determined after inferring&#34;</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">&lt;genexpr&gt;</span><span class=\"ansi-blue-fg\">(.0)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    438</span>         <span class=\"ansi-green-fg\">if</span> <span class=\"ansi-green-fg\">not</span> data<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    439</span>             <span class=\"ansi-green-fg\">raise</span> ValueError<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;can not infer schema from empty dataset&#34;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">--&gt; 440</span><span class=\"ansi-red-fg\">         </span>schema <span class=\"ansi-blue-fg\">=</span> reduce<span class=\"ansi-blue-fg\">(</span>_merge_type<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">(</span>_infer_schema<span class=\"ansi-blue-fg\">(</span>row<span class=\"ansi-blue-fg\">,</span> names<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">for</span> row <span class=\"ansi-green-fg\">in</span> data<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    441</span>         <span class=\"ansi-green-fg\">if</span> _has_nulltype<span class=\"ansi-blue-fg\">(</span>schema<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    442</span>             <span class=\"ansi-green-fg\">raise</span> ValueError<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;Some of types cannot be determined after inferring&#34;</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/types.py</span> in <span class=\"ansi-cyan-fg\">_infer_schema</span><span class=\"ansi-blue-fg\">(row, names)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1063</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1064</span>     <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">-&gt; 1065</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">raise</span> TypeError<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;Can not infer schema for type: %s&#34;</span> <span class=\"ansi-blue-fg\">%</span> type<span class=\"ansi-blue-fg\">(</span>row<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1066</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1067</span>     fields <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">[</span><span class=\"ansi-blue-fg\">]</span>\n\n<span class=\"ansi-red-fg\">TypeError</span>: Can not infer schema for type: &lt;class &#39;float&#39;&gt;</div>"]}}], "execution_count": 0}, {"cell_type": "markdown", "source": ["## Answer 5 (correct)"], "metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "2f909ada-99cb-406f-8df0-0f31d52f554c"}}}, {"cell_type": "code", "source": ["from pyspark.sql.types import FloatType\n\nspark.createDataFrame(throughputRates, FloatType()).show()"], "metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "c7193aa7-5004-476d-a11a-15dd3833c449"}}, "outputs": [{"output_type": "display_data", "metadata": {"application/vnd.databricks.v1+output": {"datasetInfos": [], "data": "<div class=\"ansiout\">+------+\n| value|\n+------+\n| 0.237|\n|  0.23|\n|0.2389|\n| 0.594|\n| 0.543|\n+------+\n\n</div>", "removedWidgets": [], "addedWidgets": {}, "metadata": {}, "type": "html", "arguments": {}}}, "data": {"text/html": ["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------+\n value|\n+------+\n 0.237|\n  0.23|\n0.2389|\n 0.594|\n 0.543|\n+------+\n\n</div>"]}}], "execution_count": 0}], "metadata": {"application/vnd.databricks.v1+notebook": {"notebookName": "175", "dashboards": [], "notebookMetadata": {"pythonIndentUnit": 2}, "language": "python", "widgets": {}, "notebookOrigID": 3659936412987707}}, "nbformat": 4, "nbformat_minor": 0}