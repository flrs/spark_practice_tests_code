{"cells": [{"cell_type": "markdown", "source": ["# Test 3, Question 35\n> **Hint:** In Databricks, import code for all questions via this URL:\n> \n> https://github.com/flrs/spark_practice_tests_code/raw/main/spark_practice_tests_code.dbc"], "metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "87a4339f-cc26-4446-83b0-5fd419c20c70"}}}, {"cell_type": "code", "source": ["%run ./create_transactionsDf2"], "metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "ce0bf962-8af0-4c63-8bed-7acbfb428c56"}}, "outputs": [{"output_type": "display_data", "metadata": {"application/vnd.databricks.v1+output": {"datasetInfos": [], "data": "<div class=\"ansiout\"></div>", "removedWidgets": [], "addedWidgets": {}, "metadata": {}, "type": "html", "arguments": {}}}, "data": {"text/html": ["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}], "execution_count": 0}, {"cell_type": "code", "source": ["transactionsDf.show()"], "metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "2a4a2762-dcf6-40f8-8379-dc9d687613bd"}}, "outputs": [{"output_type": "display_data", "metadata": {"application/vnd.databricks.v1+output": {"datasetInfos": [], "data": "<div class=\"ansiout\">+-------------+---------+-----+-------+---------+----+---------------+\n|transactionId|predError|value|storeId|productId|   f|transactionDate|\n+-------------+---------+-----+-------+---------+----+---------------+\n|            1|        3|    4|     25|        1|null|     1587915332|\n|            2|        6|    7|      2|        2|null|     1586815312|\n|            3|        3| null|     25|        3|null|     1585824821|\n|            4|     null| null|      3|        2|null|     1583244275|\n|            5|     null| null|   null|        2|null|     1575285427|\n|            6|        3|    2|     25|        2|null|     1572733275|\n+-------------+---------+-----+-------+---------+----+---------------+\n\n</div>", "removedWidgets": [], "addedWidgets": {}, "metadata": {}, "type": "html", "arguments": {}}}, "data": {"text/html": ["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------------+---------+-----+-------+---------+----+---------------+\ntransactionId|predError|value|storeId|productId|   f|transactionDate|\n+-------------+---------+-----+-------+---------+----+---------------+\n            1|        3|    4|     25|        1|null|     1587915332|\n            2|        6|    7|      2|        2|null|     1586815312|\n            3|        3| null|     25|        3|null|     1585824821|\n            4|     null| null|      3|        2|null|     1583244275|\n            5|     null| null|   null|        2|null|     1575285427|\n            6|        3|    2|     25|        2|null|     1572733275|\n+-------------+---------+-----+-------+---------+----+---------------+\n\n</div>"]}}], "execution_count": 0}, {"cell_type": "markdown", "source": ["## Answer 1 (incorrect)"], "metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "3da08153-8385-45d8-85f4-9d1e5156ec37"}}}, {"cell_type": "code", "source": ["from pyspark.sql.functions import from_unixtime\n\ntransactionsDf.withColumn(\"transactionDateForm\", from_unixtime(\"MMM d (EEEE)\", \"transactionDate\")).show()"], "metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "741846ba-74a7-4878-9715-49e613b7b7e2"}}, "outputs": [{"output_type": "display_data", "metadata": {"application/vnd.databricks.v1+output": {"datasetInfos": [], "data": "<div class=\"ansiout\"></div>", "removedWidgets": [], "addedWidgets": {}, "metadata": {}, "type": "html", "arguments": {}}}, "data": {"text/html": ["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}, {"output_type": "display_data", "metadata": {"application/vnd.databricks.v1+output": {"data": "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">AnalysisException</span>                         Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3953389280462181&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-green-fg\">from</span> pyspark<span class=\"ansi-blue-fg\">.</span>sql<span class=\"ansi-blue-fg\">.</span>functions <span class=\"ansi-green-fg\">import</span> from_unixtime\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> \n<span class=\"ansi-green-fg\">----&gt; 3</span><span class=\"ansi-red-fg\"> </span>transactionsDf<span class=\"ansi-blue-fg\">.</span>withColumn<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;transactionDateForm&#34;</span><span class=\"ansi-blue-fg\">,</span> from_unixtime<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;MMM d (EEEE)&#34;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;transactionDate&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>show<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/dataframe.py</span> in <span class=\"ansi-cyan-fg\">withColumn</span><span class=\"ansi-blue-fg\">(self, colName, col)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   2476</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-intense-fg ansi-bold\">   2477</span>         <span class=\"ansi-green-fg\">assert</span> isinstance<span class=\"ansi-blue-fg\">(</span>col<span class=\"ansi-blue-fg\">,</span> Column<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;col should be Column&#34;</span>\n<span class=\"ansi-green-fg\">-&gt; 2478</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> DataFrame<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jdf<span class=\"ansi-blue-fg\">.</span>withColumn<span class=\"ansi-blue-fg\">(</span>colName<span class=\"ansi-blue-fg\">,</span> col<span class=\"ansi-blue-fg\">.</span>_jc<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>sql_ctx<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   2479</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   2480</span>     <span class=\"ansi-green-fg\">def</span> withColumnRenamed<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> existing<span class=\"ansi-blue-fg\">,</span> new<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1302</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">-&gt; 1304</span><span class=\"ansi-red-fg\">         return_value = get_return_value(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1305</span>             answer, self.gateway_client, self.target_id, self.name)\n<span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    121</span>                 <span class=\"ansi-red-fg\"># Hide where the exception came from that shows a non-Pythonic</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    122</span>                 <span class=\"ansi-red-fg\"># JVM exception message.</span>\n<span class=\"ansi-green-fg\">--&gt; 123</span><span class=\"ansi-red-fg\">                 </span><span class=\"ansi-green-fg\">raise</span> converted <span class=\"ansi-green-fg\">from</span> <span class=\"ansi-green-fg\">None</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    124</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    125</span>                 <span class=\"ansi-green-fg\">raise</span>\n\n<span class=\"ansi-red-fg\">AnalysisException</span>: cannot resolve &#39;`MMM d (EEEE)`&#39; given input columns: [f, predError, productId, storeId, transactionDate, transactionId, value];\n&#39;Project [transactionId#6, predError#7, value#8, storeId#9, productId#10, f#11, transactionDate#19, from_unixtime(&#39;MMM d (EEEE), transactionDate, Some(Etc/UTC)) AS transactionDateForm#214]\n+- Project [transactionId#6, predError#7, value#8, storeId#9, productId#10, f#11, transactionDate#19]\n   +- Join Inner, (transactionId#6 = transactionId#18)\n      :- LogicalRDD [transactionId#6, predError#7, value#8, storeId#9, productId#10, f#11], false\n      +- LogicalRDD [transactionId#18, transactionDate#19], false\n</div>", "errorSummary": "<span class=\"ansi-red-fg\">AnalysisException</span>: cannot resolve &#39;`MMM d (EEEE)`&#39; given input columns: [f, predError, productId, storeId, transactionDate, transactionId, value];", "metadata": {}, "errorTraceType": "html", "type": "ipynbError", "arguments": {}}}, "data": {"text/html": ["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">AnalysisException</span>                         Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3953389280462181&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-green-fg\">from</span> pyspark<span class=\"ansi-blue-fg\">.</span>sql<span class=\"ansi-blue-fg\">.</span>functions <span class=\"ansi-green-fg\">import</span> from_unixtime\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> \n<span class=\"ansi-green-fg\">----&gt; 3</span><span class=\"ansi-red-fg\"> </span>transactionsDf<span class=\"ansi-blue-fg\">.</span>withColumn<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;transactionDateForm&#34;</span><span class=\"ansi-blue-fg\">,</span> from_unixtime<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;MMM d (EEEE)&#34;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;transactionDate&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>show<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/dataframe.py</span> in <span class=\"ansi-cyan-fg\">withColumn</span><span class=\"ansi-blue-fg\">(self, colName, col)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   2476</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-intense-fg ansi-bold\">   2477</span>         <span class=\"ansi-green-fg\">assert</span> isinstance<span class=\"ansi-blue-fg\">(</span>col<span class=\"ansi-blue-fg\">,</span> Column<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;col should be Column&#34;</span>\n<span class=\"ansi-green-fg\">-&gt; 2478</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> DataFrame<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jdf<span class=\"ansi-blue-fg\">.</span>withColumn<span class=\"ansi-blue-fg\">(</span>colName<span class=\"ansi-blue-fg\">,</span> col<span class=\"ansi-blue-fg\">.</span>_jc<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>sql_ctx<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   2479</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   2480</span>     <span class=\"ansi-green-fg\">def</span> withColumnRenamed<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> existing<span class=\"ansi-blue-fg\">,</span> new<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1302</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">-&gt; 1304</span><span class=\"ansi-red-fg\">         return_value = get_return_value(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1305</span>             answer, self.gateway_client, self.target_id, self.name)\n<span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    121</span>                 <span class=\"ansi-red-fg\"># Hide where the exception came from that shows a non-Pythonic</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    122</span>                 <span class=\"ansi-red-fg\"># JVM exception message.</span>\n<span class=\"ansi-green-fg\">--&gt; 123</span><span class=\"ansi-red-fg\">                 </span><span class=\"ansi-green-fg\">raise</span> converted <span class=\"ansi-green-fg\">from</span> <span class=\"ansi-green-fg\">None</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    124</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    125</span>                 <span class=\"ansi-green-fg\">raise</span>\n\n<span class=\"ansi-red-fg\">AnalysisException</span>: cannot resolve &#39;`MMM d (EEEE)`&#39; given input columns: [f, predError, productId, storeId, transactionDate, transactionId, value];\n&#39;Project [transactionId#6, predError#7, value#8, storeId#9, productId#10, f#11, transactionDate#19, from_unixtime(&#39;MMM d (EEEE), transactionDate, Some(Etc/UTC)) AS transactionDateForm#214]\n+- Project [transactionId#6, predError#7, value#8, storeId#9, productId#10, f#11, transactionDate#19]\n   +- Join Inner, (transactionId#6 = transactionId#18)\n      :- LogicalRDD [transactionId#6, predError#7, value#8, storeId#9, productId#10, f#11], false\n      +- LogicalRDD [transactionId#18, transactionDate#19], false\n</div>"]}}], "execution_count": 0}, {"cell_type": "markdown", "source": ["## Answer 2 (incorrect)"], "metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "9e7b8a51-bd8b-45ce-aed6-488cc351332a"}}}, {"cell_type": "code", "source": ["from pyspark.sql.functions import from_unixtime\n\ntransactionsDf.select(\"transactionDate\", from_unixtime(\"transactionDateForm\", \"MMM d (EEEE)\")).show()"], "metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "14f9adb3-dc1d-4e18-8cfa-4fddecdfdfcd"}}, "outputs": [{"output_type": "display_data", "metadata": {"application/vnd.databricks.v1+output": {"datasetInfos": [], "data": "<div class=\"ansiout\"></div>", "removedWidgets": [], "addedWidgets": {}, "metadata": {}, "type": "html", "arguments": {}}}, "data": {"text/html": ["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}, {"output_type": "display_data", "metadata": {"application/vnd.databricks.v1+output": {"data": "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">AnalysisException</span>                         Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3953389280462175&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-green-fg\">from</span> pyspark<span class=\"ansi-blue-fg\">.</span>sql<span class=\"ansi-blue-fg\">.</span>functions <span class=\"ansi-green-fg\">import</span> from_unixtime\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> \n<span class=\"ansi-green-fg\">----&gt; 3</span><span class=\"ansi-red-fg\"> </span>transactionsDf<span class=\"ansi-blue-fg\">.</span>select<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;transactionDate&#34;</span><span class=\"ansi-blue-fg\">,</span> from_unixtime<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;transactionDateForm&#34;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;MMM d (EEEE)&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>show<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/dataframe.py</span> in <span class=\"ansi-cyan-fg\">select</span><span class=\"ansi-blue-fg\">(self, *cols)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1690</span>         <span class=\"ansi-blue-fg\">[</span>Row<span class=\"ansi-blue-fg\">(</span>name<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#39;Alice&#39;</span><span class=\"ansi-blue-fg\">,</span> age<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">12</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> Row<span class=\"ansi-blue-fg\">(</span>name<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#39;Bob&#39;</span><span class=\"ansi-blue-fg\">,</span> age<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">15</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1691</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-fg\">-&gt; 1692</span><span class=\"ansi-red-fg\">         </span>jdf <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_jdf<span class=\"ansi-blue-fg\">.</span>select<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jcols<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>cols<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1693</span>         <span class=\"ansi-green-fg\">return</span> DataFrame<span class=\"ansi-blue-fg\">(</span>jdf<span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>sql_ctx<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1694</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1302</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">-&gt; 1304</span><span class=\"ansi-red-fg\">         return_value = get_return_value(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1305</span>             answer, self.gateway_client, self.target_id, self.name)\n<span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    121</span>                 <span class=\"ansi-red-fg\"># Hide where the exception came from that shows a non-Pythonic</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    122</span>                 <span class=\"ansi-red-fg\"># JVM exception message.</span>\n<span class=\"ansi-green-fg\">--&gt; 123</span><span class=\"ansi-red-fg\">                 </span><span class=\"ansi-green-fg\">raise</span> converted <span class=\"ansi-green-fg\">from</span> <span class=\"ansi-green-fg\">None</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    124</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    125</span>                 <span class=\"ansi-green-fg\">raise</span>\n\n<span class=\"ansi-red-fg\">AnalysisException</span>: cannot resolve &#39;`transactionDateForm`&#39; given input columns: [f, predError, productId, storeId, transactionDate, transactionId, value];\n&#39;Project [transactionDate#19, from_unixtime(&#39;transactionDateForm, MMM d (EEEE), Some(Etc/UTC)) AS from_unixtime(transactionDateForm, MMM d (EEEE))#159]\n+- Project [transactionId#6, predError#7, value#8, storeId#9, productId#10, f#11, transactionDate#19]\n   +- Join Inner, (transactionId#6 = transactionId#18)\n      :- LogicalRDD [transactionId#6, predError#7, value#8, storeId#9, productId#10, f#11], false\n      +- LogicalRDD [transactionId#18, transactionDate#19], false\n</div>", "errorSummary": "<span class=\"ansi-red-fg\">AnalysisException</span>: cannot resolve &#39;`transactionDateForm`&#39; given input columns: [f, predError, productId, storeId, transactionDate, transactionId, value];", "metadata": {}, "errorTraceType": "html", "type": "ipynbError", "arguments": {}}}, "data": {"text/html": ["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">AnalysisException</span>                         Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3953389280462175&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-green-fg\">from</span> pyspark<span class=\"ansi-blue-fg\">.</span>sql<span class=\"ansi-blue-fg\">.</span>functions <span class=\"ansi-green-fg\">import</span> from_unixtime\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> \n<span class=\"ansi-green-fg\">----&gt; 3</span><span class=\"ansi-red-fg\"> </span>transactionsDf<span class=\"ansi-blue-fg\">.</span>select<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;transactionDate&#34;</span><span class=\"ansi-blue-fg\">,</span> from_unixtime<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;transactionDateForm&#34;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;MMM d (EEEE)&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>show<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/dataframe.py</span> in <span class=\"ansi-cyan-fg\">select</span><span class=\"ansi-blue-fg\">(self, *cols)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1690</span>         <span class=\"ansi-blue-fg\">[</span>Row<span class=\"ansi-blue-fg\">(</span>name<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#39;Alice&#39;</span><span class=\"ansi-blue-fg\">,</span> age<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">12</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> Row<span class=\"ansi-blue-fg\">(</span>name<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#39;Bob&#39;</span><span class=\"ansi-blue-fg\">,</span> age<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">15</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1691</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-fg\">-&gt; 1692</span><span class=\"ansi-red-fg\">         </span>jdf <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_jdf<span class=\"ansi-blue-fg\">.</span>select<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jcols<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>cols<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1693</span>         <span class=\"ansi-green-fg\">return</span> DataFrame<span class=\"ansi-blue-fg\">(</span>jdf<span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>sql_ctx<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1694</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1302</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">-&gt; 1304</span><span class=\"ansi-red-fg\">         return_value = get_return_value(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1305</span>             answer, self.gateway_client, self.target_id, self.name)\n<span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    121</span>                 <span class=\"ansi-red-fg\"># Hide where the exception came from that shows a non-Pythonic</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    122</span>                 <span class=\"ansi-red-fg\"># JVM exception message.</span>\n<span class=\"ansi-green-fg\">--&gt; 123</span><span class=\"ansi-red-fg\">                 </span><span class=\"ansi-green-fg\">raise</span> converted <span class=\"ansi-green-fg\">from</span> <span class=\"ansi-green-fg\">None</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    124</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    125</span>                 <span class=\"ansi-green-fg\">raise</span>\n\n<span class=\"ansi-red-fg\">AnalysisException</span>: cannot resolve &#39;`transactionDateForm`&#39; given input columns: [f, predError, productId, storeId, transactionDate, transactionId, value];\n&#39;Project [transactionDate#19, from_unixtime(&#39;transactionDateForm, MMM d (EEEE), Some(Etc/UTC)) AS from_unixtime(transactionDateForm, MMM d (EEEE))#159]\n+- Project [transactionId#6, predError#7, value#8, storeId#9, productId#10, f#11, transactionDate#19]\n   +- Join Inner, (transactionId#6 = transactionId#18)\n      :- LogicalRDD [transactionId#6, predError#7, value#8, storeId#9, productId#10, f#11], false\n      +- LogicalRDD [transactionId#18, transactionDate#19], false\n</div>"]}}], "execution_count": 0}, {"cell_type": "markdown", "source": ["## Answer 3 (correct)"], "metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "2f909ada-99cb-406f-8df0-0f31d52f554c"}}}, {"cell_type": "code", "source": ["from pyspark.sql.functions import from_unixtime\n\ntransactionsDf.withColumn(\"transactionDateForm\", from_unixtime(\"transactionDate\", \"MMM d (EEEE)\")).show()"], "metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "c7193aa7-5004-476d-a11a-15dd3833c449"}}, "outputs": [{"output_type": "display_data", "metadata": {"application/vnd.databricks.v1+output": {"datasetInfos": [], "data": "<div class=\"ansiout\">+-------------+---------+-----+-------+---------+----+---------------+-------------------+\n|transactionId|predError|value|storeId|productId|   f|transactionDate|transactionDateForm|\n+-------------+---------+-----+-------+---------+----+---------------+-------------------+\n|            1|        3|    4|     25|        1|null|     1587915332|    Apr 26 (Sunday)|\n|            2|        6|    7|      2|        2|null|     1586815312|    Apr 13 (Monday)|\n|            3|        3| null|     25|        3|null|     1585824821|   Apr 2 (Thursday)|\n|            4|     null| null|      3|        2|null|     1583244275|    Mar 3 (Tuesday)|\n|            5|     null| null|   null|        2|null|     1575285427|     Dec 2 (Monday)|\n|            6|        3|    2|     25|        2|null|     1572733275|   Nov 2 (Saturday)|\n+-------------+---------+-----+-------+---------+----+---------------+-------------------+\n\n</div>", "removedWidgets": [], "addedWidgets": {}, "metadata": {}, "type": "html", "arguments": {}}}, "data": {"text/html": ["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------------+---------+-----+-------+---------+----+---------------+-------------------+\ntransactionId|predError|value|storeId|productId|   f|transactionDate|transactionDateForm|\n+-------------+---------+-----+-------+---------+----+---------------+-------------------+\n            1|        3|    4|     25|        1|null|     1587915332|    Apr 26 (Sunday)|\n            2|        6|    7|      2|        2|null|     1586815312|    Apr 13 (Monday)|\n            3|        3| null|     25|        3|null|     1585824821|   Apr 2 (Thursday)|\n            4|     null| null|      3|        2|null|     1583244275|    Mar 3 (Tuesday)|\n            5|     null| null|   null|        2|null|     1575285427|     Dec 2 (Monday)|\n            6|        3|    2|     25|        2|null|     1572733275|   Nov 2 (Saturday)|\n+-------------+---------+-----+-------+---------+----+---------------+-------------------+\n\n</div>"]}}], "execution_count": 0}, {"cell_type": "markdown", "source": ["## Answer 4 (incorrect)"], "metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "8fef6132-53bf-4c40-b876-e17972c28fe8"}}}, {"cell_type": "code", "source": ["from pyspark.sql.functions import from_unixtime\n\ntransactionsDf.withColumn(\"transactionDateForm\", from_unixtime(\"transactionDate\", \"MM d (EEE)\")).show()"], "metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "4a1dfb7c-aaf8-4c46-89c0-7367cb77a413"}}, "outputs": [{"output_type": "display_data", "metadata": {"application/vnd.databricks.v1+output": {"datasetInfos": [], "data": "<div class=\"ansiout\">+-------------+---------+-----+-------+---------+----+---------------+-------------------+\n|transactionId|predError|value|storeId|productId|   f|transactionDate|transactionDateForm|\n+-------------+---------+-----+-------+---------+----+---------------+-------------------+\n|            1|        3|    4|     25|        1|null|     1587915332|        04 26 (Sun)|\n|            2|        6|    7|      2|        2|null|     1586815312|        04 13 (Mon)|\n|            3|        3| null|     25|        3|null|     1585824821|         04 2 (Thu)|\n|            4|     null| null|      3|        2|null|     1583244275|         03 3 (Tue)|\n|            5|     null| null|   null|        2|null|     1575285427|         12 2 (Mon)|\n|            6|        3|    2|     25|        2|null|     1572733275|         11 2 (Sat)|\n+-------------+---------+-----+-------+---------+----+---------------+-------------------+\n\n</div>", "removedWidgets": [], "addedWidgets": {}, "metadata": {}, "type": "html", "arguments": {}}}, "data": {"text/html": ["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------------+---------+-----+-------+---------+----+---------------+-------------------+\ntransactionId|predError|value|storeId|productId|   f|transactionDate|transactionDateForm|\n+-------------+---------+-----+-------+---------+----+---------------+-------------------+\n            1|        3|    4|     25|        1|null|     1587915332|        04 26 (Sun)|\n            2|        6|    7|      2|        2|null|     1586815312|        04 13 (Mon)|\n            3|        3| null|     25|        3|null|     1585824821|         04 2 (Thu)|\n            4|     null| null|      3|        2|null|     1583244275|         03 3 (Tue)|\n            5|     null| null|   null|        2|null|     1575285427|         12 2 (Mon)|\n            6|        3|    2|     25|        2|null|     1572733275|         11 2 (Sat)|\n+-------------+---------+-----+-------+---------+----+---------------+-------------------+\n\n</div>"]}}], "execution_count": 0}, {"cell_type": "markdown", "source": ["## Answer 5 (incorrect)"], "metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "9edca3fe-7135-4cbe-a61a-a5dbd2d4c733"}}}, {"cell_type": "code", "source": ["from pyspark.sql.functions import from_unixtime\n\ntransactionsDf.withColumnRenamed(\"transactionDate\", from_unixtime(\"transactionDateForm\", \"MM d (EEE)\")).show()"], "metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "6c3f712f-0536-4ce8-ad81-b36c5ec71945"}}, "outputs": [{"output_type": "display_data", "metadata": {"application/vnd.databricks.v1+output": {"datasetInfos": [], "data": "<div class=\"ansiout\"></div>", "removedWidgets": [], "addedWidgets": {}, "metadata": {}, "type": "html", "arguments": {}}}, "data": {"text/html": ["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}, {"output_type": "display_data", "metadata": {"application/vnd.databricks.v1+output": {"data": "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">TypeError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3953389280462179&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-green-fg\">from</span> pyspark<span class=\"ansi-blue-fg\">.</span>sql<span class=\"ansi-blue-fg\">.</span>functions <span class=\"ansi-green-fg\">import</span> from_unixtime\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> \n<span class=\"ansi-green-fg\">----&gt; 3</span><span class=\"ansi-red-fg\"> </span>transactionsDf<span class=\"ansi-blue-fg\">.</span>withColumnRenamed<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;transactionDate&#34;</span><span class=\"ansi-blue-fg\">,</span> from_unixtime<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;transactionDateForm&#34;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;MM d (EEE)&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>show<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/dataframe.py</span> in <span class=\"ansi-cyan-fg\">withColumnRenamed</span><span class=\"ansi-blue-fg\">(self, existing, new)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   2496</span>         <span class=\"ansi-blue-fg\">[</span>Row<span class=\"ansi-blue-fg\">(</span>age2<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">2</span><span class=\"ansi-blue-fg\">,</span> name<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#39;Alice&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> Row<span class=\"ansi-blue-fg\">(</span>age2<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">5</span><span class=\"ansi-blue-fg\">,</span> name<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#39;Bob&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   2497</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-fg\">-&gt; 2498</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> DataFrame<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jdf<span class=\"ansi-blue-fg\">.</span>withColumnRenamed<span class=\"ansi-blue-fg\">(</span>existing<span class=\"ansi-blue-fg\">,</span> new<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>sql_ctx<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   2499</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   2500</span>     <span class=\"ansi-green-fg\">def</span> drop<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">*</span>cols<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1294</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1295</span>     <span class=\"ansi-green-fg\">def</span> __call__<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">*</span>args<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">-&gt; 1296</span><span class=\"ansi-red-fg\">         </span>args_command<span class=\"ansi-blue-fg\">,</span> temp_args <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_build_args<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>args<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1297</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1298</span>         command <span class=\"ansi-blue-fg\">=</span> proto<span class=\"ansi-blue-fg\">.</span>CALL_COMMAND_NAME <span class=\"ansi-blue-fg\">+</span><span class=\"ansi-red-fg\">\\</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">_build_args</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1258</span>     <span class=\"ansi-green-fg\">def</span> _build_args<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">*</span>args<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1259</span>         <span class=\"ansi-green-fg\">if</span> self<span class=\"ansi-blue-fg\">.</span>converters <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">not</span> <span class=\"ansi-green-fg\">None</span> <span class=\"ansi-green-fg\">and</span> len<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>converters<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">&gt;</span> <span class=\"ansi-cyan-fg\">0</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">-&gt; 1260</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-blue-fg\">(</span>new_args<span class=\"ansi-blue-fg\">,</span> temp_args<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_get_args<span class=\"ansi-blue-fg\">(</span>args<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1261</span>         <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1262</span>             new_args <span class=\"ansi-blue-fg\">=</span> args\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">_get_args</span><span class=\"ansi-blue-fg\">(self, args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1245</span>                 <span class=\"ansi-green-fg\">for</span> converter <span class=\"ansi-green-fg\">in</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>converters<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1246</span>                     <span class=\"ansi-green-fg\">if</span> converter<span class=\"ansi-blue-fg\">.</span>can_convert<span class=\"ansi-blue-fg\">(</span>arg<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">-&gt; 1247</span><span class=\"ansi-red-fg\">                         </span>temp_arg <span class=\"ansi-blue-fg\">=</span> converter<span class=\"ansi-blue-fg\">.</span>convert<span class=\"ansi-blue-fg\">(</span>arg<span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1248</span>                         temp_args<span class=\"ansi-blue-fg\">.</span>append<span class=\"ansi-blue-fg\">(</span>temp_arg<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1249</span>                         new_args<span class=\"ansi-blue-fg\">.</span>append<span class=\"ansi-blue-fg\">(</span>temp_arg<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_collections.py</span> in <span class=\"ansi-cyan-fg\">convert</span><span class=\"ansi-blue-fg\">(self, object, gateway_client)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    508</span>         ArrayList <span class=\"ansi-blue-fg\">=</span> JavaClass<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;java.util.ArrayList&#34;</span><span class=\"ansi-blue-fg\">,</span> gateway_client<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    509</span>         java_list <span class=\"ansi-blue-fg\">=</span> ArrayList<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">--&gt; 510</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">for</span> element <span class=\"ansi-green-fg\">in</span> object<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    511</span>             java_list<span class=\"ansi-blue-fg\">.</span>add<span class=\"ansi-blue-fg\">(</span>element<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    512</span>         <span class=\"ansi-green-fg\">return</span> java_list\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/column.py</span> in <span class=\"ansi-cyan-fg\">__iter__</span><span class=\"ansi-blue-fg\">(self)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    467</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    468</span>     <span class=\"ansi-green-fg\">def</span> __iter__<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 469</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">raise</span> TypeError<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;Column is not iterable&#34;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    470</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    471</span>     <span class=\"ansi-red-fg\"># string methods</span>\n\n<span class=\"ansi-red-fg\">TypeError</span>: Column is not iterable</div>", "errorSummary": "<span class=\"ansi-red-fg\">TypeError</span>: Column is not iterable", "metadata": {}, "errorTraceType": "html", "type": "ipynbError", "arguments": {}}}, "data": {"text/html": ["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">TypeError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3953389280462179&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-green-fg\">from</span> pyspark<span class=\"ansi-blue-fg\">.</span>sql<span class=\"ansi-blue-fg\">.</span>functions <span class=\"ansi-green-fg\">import</span> from_unixtime\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> \n<span class=\"ansi-green-fg\">----&gt; 3</span><span class=\"ansi-red-fg\"> </span>transactionsDf<span class=\"ansi-blue-fg\">.</span>withColumnRenamed<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;transactionDate&#34;</span><span class=\"ansi-blue-fg\">,</span> from_unixtime<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;transactionDateForm&#34;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;MM d (EEE)&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>show<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/dataframe.py</span> in <span class=\"ansi-cyan-fg\">withColumnRenamed</span><span class=\"ansi-blue-fg\">(self, existing, new)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   2496</span>         <span class=\"ansi-blue-fg\">[</span>Row<span class=\"ansi-blue-fg\">(</span>age2<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">2</span><span class=\"ansi-blue-fg\">,</span> name<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#39;Alice&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> Row<span class=\"ansi-blue-fg\">(</span>age2<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">5</span><span class=\"ansi-blue-fg\">,</span> name<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#39;Bob&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   2497</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-fg\">-&gt; 2498</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> DataFrame<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jdf<span class=\"ansi-blue-fg\">.</span>withColumnRenamed<span class=\"ansi-blue-fg\">(</span>existing<span class=\"ansi-blue-fg\">,</span> new<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>sql_ctx<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   2499</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   2500</span>     <span class=\"ansi-green-fg\">def</span> drop<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">*</span>cols<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1294</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1295</span>     <span class=\"ansi-green-fg\">def</span> __call__<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">*</span>args<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">-&gt; 1296</span><span class=\"ansi-red-fg\">         </span>args_command<span class=\"ansi-blue-fg\">,</span> temp_args <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_build_args<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>args<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1297</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1298</span>         command <span class=\"ansi-blue-fg\">=</span> proto<span class=\"ansi-blue-fg\">.</span>CALL_COMMAND_NAME <span class=\"ansi-blue-fg\">+</span><span class=\"ansi-red-fg\">\\</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">_build_args</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1258</span>     <span class=\"ansi-green-fg\">def</span> _build_args<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">*</span>args<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1259</span>         <span class=\"ansi-green-fg\">if</span> self<span class=\"ansi-blue-fg\">.</span>converters <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">not</span> <span class=\"ansi-green-fg\">None</span> <span class=\"ansi-green-fg\">and</span> len<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>converters<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">&gt;</span> <span class=\"ansi-cyan-fg\">0</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">-&gt; 1260</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-blue-fg\">(</span>new_args<span class=\"ansi-blue-fg\">,</span> temp_args<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_get_args<span class=\"ansi-blue-fg\">(</span>args<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1261</span>         <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1262</span>             new_args <span class=\"ansi-blue-fg\">=</span> args\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">_get_args</span><span class=\"ansi-blue-fg\">(self, args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1245</span>                 <span class=\"ansi-green-fg\">for</span> converter <span class=\"ansi-green-fg\">in</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>converters<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1246</span>                     <span class=\"ansi-green-fg\">if</span> converter<span class=\"ansi-blue-fg\">.</span>can_convert<span class=\"ansi-blue-fg\">(</span>arg<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">-&gt; 1247</span><span class=\"ansi-red-fg\">                         </span>temp_arg <span class=\"ansi-blue-fg\">=</span> converter<span class=\"ansi-blue-fg\">.</span>convert<span class=\"ansi-blue-fg\">(</span>arg<span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1248</span>                         temp_args<span class=\"ansi-blue-fg\">.</span>append<span class=\"ansi-blue-fg\">(</span>temp_arg<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1249</span>                         new_args<span class=\"ansi-blue-fg\">.</span>append<span class=\"ansi-blue-fg\">(</span>temp_arg<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_collections.py</span> in <span class=\"ansi-cyan-fg\">convert</span><span class=\"ansi-blue-fg\">(self, object, gateway_client)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    508</span>         ArrayList <span class=\"ansi-blue-fg\">=</span> JavaClass<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;java.util.ArrayList&#34;</span><span class=\"ansi-blue-fg\">,</span> gateway_client<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    509</span>         java_list <span class=\"ansi-blue-fg\">=</span> ArrayList<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">--&gt; 510</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">for</span> element <span class=\"ansi-green-fg\">in</span> object<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    511</span>             java_list<span class=\"ansi-blue-fg\">.</span>add<span class=\"ansi-blue-fg\">(</span>element<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    512</span>         <span class=\"ansi-green-fg\">return</span> java_list\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/column.py</span> in <span class=\"ansi-cyan-fg\">__iter__</span><span class=\"ansi-blue-fg\">(self)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    467</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    468</span>     <span class=\"ansi-green-fg\">def</span> __iter__<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 469</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">raise</span> TypeError<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;Column is not iterable&#34;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    470</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    471</span>     <span class=\"ansi-red-fg\"># string methods</span>\n\n<span class=\"ansi-red-fg\">TypeError</span>: Column is not iterable</div>"]}}], "execution_count": 0}], "metadata": {"application/vnd.databricks.v1+notebook": {"notebookName": "155", "dashboards": [], "notebookMetadata": {"pythonIndentUnit": 2}, "language": "python", "widgets": {}, "notebookOrigID": 3953389280462169}}, "nbformat": 4, "nbformat_minor": 0}