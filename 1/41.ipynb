{"cells": [{"cell_type": "markdown", "source": ["# Test 1, Question 41"], "metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "87a4339f-cc26-4446-83b0-5fd419c20c70"}}}, {"cell_type": "markdown", "source": ["## Answer 1 (incorrect)"], "metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "3da08153-8385-45d8-85f4-9d1e5156ec37"}}}, {"cell_type": "code", "source": ["spark.DataFrame({\"season\": [\"winter\",\"summer\"], \"wind_speed_ms\": [4.5, 7.5]}).show()"], "metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "741846ba-74a7-4878-9715-49e613b7b7e2"}}, "outputs": [{"output_type": "display_data", "metadata": {"application/vnd.databricks.v1+output": {"datasetInfos": [], "data": "<div class=\"ansiout\"></div>", "removedWidgets": [], "addedWidgets": {}, "metadata": {}, "type": "html", "arguments": {}}}, "data": {"text/html": ["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}, {"output_type": "display_data", "metadata": {"application/vnd.databricks.v1+output": {"data": "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">AttributeError</span>                            Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-2168700272281629&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span>spark<span class=\"ansi-blue-fg\">.</span>DataFrame<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">{</span><span class=\"ansi-blue-fg\">&#34;season&#34;</span><span class=\"ansi-blue-fg\">:</span> <span class=\"ansi-blue-fg\">[</span><span class=\"ansi-blue-fg\">&#34;winter&#34;</span><span class=\"ansi-blue-fg\">,</span><span class=\"ansi-blue-fg\">&#34;summer&#34;</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;wind_speed_ms&#34;</span><span class=\"ansi-blue-fg\">:</span> <span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">4.5</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">7.5</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">}</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>show<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-red-fg\">AttributeError</span>: &#39;SparkSession&#39; object has no attribute &#39;DataFrame&#39;</div>", "errorSummary": "<span class=\"ansi-red-fg\">AttributeError</span>: &#39;SparkSession&#39; object has no attribute &#39;DataFrame&#39;", "metadata": {}, "errorTraceType": "html", "type": "ipynbError", "arguments": {}}}, "data": {"text/html": ["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">AttributeError</span>                            Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-2168700272281629&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span>spark<span class=\"ansi-blue-fg\">.</span>DataFrame<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">{</span><span class=\"ansi-blue-fg\">&#34;season&#34;</span><span class=\"ansi-blue-fg\">:</span> <span class=\"ansi-blue-fg\">[</span><span class=\"ansi-blue-fg\">&#34;winter&#34;</span><span class=\"ansi-blue-fg\">,</span><span class=\"ansi-blue-fg\">&#34;summer&#34;</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;wind_speed_ms&#34;</span><span class=\"ansi-blue-fg\">:</span> <span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">4.5</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">7.5</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">}</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>show<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-red-fg\">AttributeError</span>: &#39;SparkSession&#39; object has no attribute &#39;DataFrame&#39;</div>"]}}], "execution_count": 0}, {"cell_type": "markdown", "source": ["## Answer 2 (correct)"], "metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "2f909ada-99cb-406f-8df0-0f31d52f554c"}}}, {"cell_type": "code", "source": ["spark.createDataFrame([(\"summer\", 4.5), (\"winter\", 7.5)], [\"season\", \"wind_speed_ms\"]).show()"], "metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "c7193aa7-5004-476d-a11a-15dd3833c449"}}, "outputs": [{"output_type": "display_data", "metadata": {"application/vnd.databricks.v1+output": {"datasetInfos": [], "data": "<div class=\"ansiout\">+------+-------------+\n|season|wind_speed_ms|\n+------+-------------+\n|summer|          4.5|\n|winter|          7.5|\n+------+-------------+\n\n</div>", "removedWidgets": [], "addedWidgets": {}, "metadata": {}, "type": "html", "arguments": {}}}, "data": {"text/html": ["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------+-------------+\nseason|wind_speed_ms|\n+------+-------------+\nsummer|          4.5|\nwinter|          7.5|\n+------+-------------+\n\n</div>"]}}], "execution_count": 0}, {"cell_type": "markdown", "source": ["## Answer 3 (incorrect)"], "metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "8fef6132-53bf-4c40-b876-e17972c28fe8"}}}, {"cell_type": "code", "source": ["from pyspark.sql import types as T\n\nspark.createDataFrame(((\"summer\", 4.5), (\"winter\", 7.5)), T.StructType([T.StructField(\"season\", T.CharType()), T.StructField(\"season\", T.DoubleType())])).show()"], "metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "4a1dfb7c-aaf8-4c46-89c0-7367cb77a413"}}, "outputs": [{"output_type": "display_data", "metadata": {"application/vnd.databricks.v1+output": {"datasetInfos": [], "data": "<div class=\"ansiout\"></div>", "removedWidgets": [], "addedWidgets": {}, "metadata": {}, "type": "html", "arguments": {}}}, "data": {"text/html": ["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}, {"output_type": "display_data", "metadata": {"application/vnd.databricks.v1+output": {"data": "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">AttributeError</span>                            Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-2168700272281625&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-green-fg\">from</span> pyspark<span class=\"ansi-blue-fg\">.</span>sql <span class=\"ansi-green-fg\">import</span> types <span class=\"ansi-green-fg\">as</span> T\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> \n<span class=\"ansi-green-fg\">----&gt; 3</span><span class=\"ansi-red-fg\"> </span>spark<span class=\"ansi-blue-fg\">.</span>createDataFrame<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;summer&#34;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">4.5</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;winter&#34;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">7.5</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> T<span class=\"ansi-blue-fg\">.</span>StructType<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">[</span>T<span class=\"ansi-blue-fg\">.</span>StructField<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;season&#34;</span><span class=\"ansi-blue-fg\">,</span> T<span class=\"ansi-blue-fg\">.</span>CharType<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> T<span class=\"ansi-blue-fg\">.</span>StructField<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;season&#34;</span><span class=\"ansi-blue-fg\">,</span> T<span class=\"ansi-blue-fg\">.</span>DoubleType<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>show<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-red-fg\">AttributeError</span>: module &#39;pyspark.sql.types&#39; has no attribute &#39;CharType&#39;</div>", "errorSummary": "<span class=\"ansi-red-fg\">AttributeError</span>: module &#39;pyspark.sql.types&#39; has no attribute &#39;CharType&#39;", "metadata": {}, "errorTraceType": "html", "type": "ipynbError", "arguments": {}}}, "data": {"text/html": ["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">AttributeError</span>                            Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-2168700272281625&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-green-fg\">from</span> pyspark<span class=\"ansi-blue-fg\">.</span>sql <span class=\"ansi-green-fg\">import</span> types <span class=\"ansi-green-fg\">as</span> T\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> \n<span class=\"ansi-green-fg\">----&gt; 3</span><span class=\"ansi-red-fg\"> </span>spark<span class=\"ansi-blue-fg\">.</span>createDataFrame<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;summer&#34;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">4.5</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;winter&#34;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">7.5</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> T<span class=\"ansi-blue-fg\">.</span>StructType<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">[</span>T<span class=\"ansi-blue-fg\">.</span>StructField<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;season&#34;</span><span class=\"ansi-blue-fg\">,</span> T<span class=\"ansi-blue-fg\">.</span>CharType<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> T<span class=\"ansi-blue-fg\">.</span>StructField<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;season&#34;</span><span class=\"ansi-blue-fg\">,</span> T<span class=\"ansi-blue-fg\">.</span>DoubleType<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>show<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-red-fg\">AttributeError</span>: module &#39;pyspark.sql.types&#39; has no attribute &#39;CharType&#39;</div>"]}}], "execution_count": 0}, {"cell_type": "markdown", "source": ["## Answer 4 (incorrect)"], "metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "9e7b8a51-bd8b-45ce-aed6-488cc351332a"}}}, {"cell_type": "code", "source": ["spark.newDataFrame([(\"summer\", 4.5), (\"winter\", 7.5)], [\"season\", \"wind_speed_ms\"]).show()"], "metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "14f9adb3-dc1d-4e18-8cfa-4fddecdfdfcd"}}, "outputs": [{"output_type": "display_data", "metadata": {"application/vnd.databricks.v1+output": {"datasetInfos": [], "data": "<div class=\"ansiout\"></div>", "removedWidgets": [], "addedWidgets": {}, "metadata": {}, "type": "html", "arguments": {}}}, "data": {"text/html": ["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}, {"output_type": "display_data", "metadata": {"application/vnd.databricks.v1+output": {"data": "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">AttributeError</span>                            Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-2168700272281623&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span>spark<span class=\"ansi-blue-fg\">.</span>newDataFrame<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">[</span><span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;summer&#34;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">4.5</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;winter&#34;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">7.5</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">[</span><span class=\"ansi-blue-fg\">&#34;season&#34;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;wind_speed_ms&#34;</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>show<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-red-fg\">AttributeError</span>: &#39;SparkSession&#39; object has no attribute &#39;newDataFrame&#39;</div>", "errorSummary": "<span class=\"ansi-red-fg\">AttributeError</span>: &#39;SparkSession&#39; object has no attribute &#39;newDataFrame&#39;", "metadata": {}, "errorTraceType": "html", "type": "ipynbError", "arguments": {}}}, "data": {"text/html": ["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">AttributeError</span>                            Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-2168700272281623&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span>spark<span class=\"ansi-blue-fg\">.</span>newDataFrame<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">[</span><span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;summer&#34;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">4.5</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;winter&#34;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">7.5</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">[</span><span class=\"ansi-blue-fg\">&#34;season&#34;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;wind_speed_ms&#34;</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>show<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-red-fg\">AttributeError</span>: &#39;SparkSession&#39; object has no attribute &#39;newDataFrame&#39;</div>"]}}], "execution_count": 0}, {"cell_type": "markdown", "source": ["## Answer 5 (incorrect)"], "metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "9edca3fe-7135-4cbe-a61a-a5dbd2d4c733"}}}, {"cell_type": "code", "source": ["spark.createDataFrame({\"season\": [\"winter\",\"summer\"], \"wind_speed_ms\": [4.5, 7.5]}).show()"], "metadata": {"application/vnd.databricks.v1+cell": {"title": "", "showTitle": false, "inputWidgets": {}, "nuid": "6c3f712f-0536-4ce8-ad81-b36c5ec71945"}}, "outputs": [{"output_type": "display_data", "metadata": {"application/vnd.databricks.v1+output": {"datasetInfos": [], "data": "<div class=\"ansiout\"></div>", "removedWidgets": [], "addedWidgets": {}, "metadata": {}, "type": "html", "arguments": {}}}, "data": {"text/html": ["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}, {"output_type": "display_data", "metadata": {"application/vnd.databricks.v1+output": {"data": "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">TypeError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-2168700272281627&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span>spark<span class=\"ansi-blue-fg\">.</span>createDataFrame<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">{</span><span class=\"ansi-blue-fg\">&#34;season&#34;</span><span class=\"ansi-blue-fg\">:</span> <span class=\"ansi-blue-fg\">[</span><span class=\"ansi-blue-fg\">&#34;winter&#34;</span><span class=\"ansi-blue-fg\">,</span><span class=\"ansi-blue-fg\">&#34;summer&#34;</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;wind_speed_ms&#34;</span><span class=\"ansi-blue-fg\">:</span> <span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">4.5</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">7.5</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">}</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>show<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">createDataFrame</span><span class=\"ansi-blue-fg\">(self, data, schema, samplingRatio, verifySchema)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    720</span>             return super(SparkSession, self).createDataFrame(\n<span class=\"ansi-green-intense-fg ansi-bold\">    721</span>                 data, schema, samplingRatio, verifySchema)\n<span class=\"ansi-green-fg\">--&gt; 722</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_create_dataframe<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">,</span> samplingRatio<span class=\"ansi-blue-fg\">,</span> verifySchema<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    723</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    724</span>     <span class=\"ansi-green-fg\">def</span> _create_dataframe<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> data<span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">,</span> samplingRatio<span class=\"ansi-blue-fg\">,</span> verifySchema<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">_create_dataframe</span><span class=\"ansi-blue-fg\">(self, data, schema, samplingRatio, verifySchema)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    752</span>                 rdd<span class=\"ansi-blue-fg\">,</span> schema <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_createFromRDD<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">.</span>map<span class=\"ansi-blue-fg\">(</span>prepare<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">,</span> samplingRatio<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    753</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 754</span><span class=\"ansi-red-fg\">                 </span>rdd<span class=\"ansi-blue-fg\">,</span> schema <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_createFromLocal<span class=\"ansi-blue-fg\">(</span>map<span class=\"ansi-blue-fg\">(</span>prepare<span class=\"ansi-blue-fg\">,</span> data<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    755</span>             jrdd <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_jvm<span class=\"ansi-blue-fg\">.</span>SerDeUtil<span class=\"ansi-blue-fg\">.</span>toJavaArray<span class=\"ansi-blue-fg\">(</span>rdd<span class=\"ansi-blue-fg\">.</span>_to_java_object_rdd<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    756</span>             jdf <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_jsparkSession<span class=\"ansi-blue-fg\">.</span>applySchemaToPythonRDD<span class=\"ansi-blue-fg\">(</span>jrdd<span class=\"ansi-blue-fg\">.</span>rdd<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">.</span>json<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">_createFromLocal</span><span class=\"ansi-blue-fg\">(self, data, schema)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    528</span>         write temp files<span class=\"ansi-blue-fg\">.</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    529</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-fg\">--&gt; 530</span><span class=\"ansi-red-fg\">         </span>data<span class=\"ansi-blue-fg\">,</span> schema <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_wrap_data_schema<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    531</span>         <span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_sc<span class=\"ansi-blue-fg\">.</span>parallelize<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> schema\n<span class=\"ansi-green-intense-fg ansi-bold\">    532</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">_wrap_data_schema</span><span class=\"ansi-blue-fg\">(self, data, schema)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    507</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    508</span>         <span class=\"ansi-green-fg\">if</span> schema <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">None</span> <span class=\"ansi-green-fg\">or</span> isinstance<span class=\"ansi-blue-fg\">(</span>schema<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">(</span>list<span class=\"ansi-blue-fg\">,</span> tuple<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 509</span><span class=\"ansi-red-fg\">             </span>struct <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_inferSchemaFromList<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">,</span> names<span class=\"ansi-blue-fg\">=</span>schema<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    510</span>             converter <span class=\"ansi-blue-fg\">=</span> _create_converter<span class=\"ansi-blue-fg\">(</span>struct<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    511</span>             data <span class=\"ansi-blue-fg\">=</span> map<span class=\"ansi-blue-fg\">(</span>converter<span class=\"ansi-blue-fg\">,</span> data<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">_inferSchemaFromList</span><span class=\"ansi-blue-fg\">(self, data, names)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    438</span>         <span class=\"ansi-green-fg\">if</span> <span class=\"ansi-green-fg\">not</span> data<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    439</span>             <span class=\"ansi-green-fg\">raise</span> ValueError<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;can not infer schema from empty dataset&#34;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">--&gt; 440</span><span class=\"ansi-red-fg\">         </span>schema <span class=\"ansi-blue-fg\">=</span> reduce<span class=\"ansi-blue-fg\">(</span>_merge_type<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">(</span>_infer_schema<span class=\"ansi-blue-fg\">(</span>row<span class=\"ansi-blue-fg\">,</span> names<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">for</span> row <span class=\"ansi-green-fg\">in</span> data<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    441</span>         <span class=\"ansi-green-fg\">if</span> _has_nulltype<span class=\"ansi-blue-fg\">(</span>schema<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    442</span>             <span class=\"ansi-green-fg\">raise</span> ValueError<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;Some of types cannot be determined after inferring&#34;</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">&lt;genexpr&gt;</span><span class=\"ansi-blue-fg\">(.0)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    438</span>         <span class=\"ansi-green-fg\">if</span> <span class=\"ansi-green-fg\">not</span> data<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    439</span>             <span class=\"ansi-green-fg\">raise</span> ValueError<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;can not infer schema from empty dataset&#34;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">--&gt; 440</span><span class=\"ansi-red-fg\">         </span>schema <span class=\"ansi-blue-fg\">=</span> reduce<span class=\"ansi-blue-fg\">(</span>_merge_type<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">(</span>_infer_schema<span class=\"ansi-blue-fg\">(</span>row<span class=\"ansi-blue-fg\">,</span> names<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">for</span> row <span class=\"ansi-green-fg\">in</span> data<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    441</span>         <span class=\"ansi-green-fg\">if</span> _has_nulltype<span class=\"ansi-blue-fg\">(</span>schema<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    442</span>             <span class=\"ansi-green-fg\">raise</span> ValueError<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;Some of types cannot be determined after inferring&#34;</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/types.py</span> in <span class=\"ansi-cyan-fg\">_infer_schema</span><span class=\"ansi-blue-fg\">(row, names)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1063</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1064</span>     <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">-&gt; 1065</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">raise</span> TypeError<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;Can not infer schema for type: %s&#34;</span> <span class=\"ansi-blue-fg\">%</span> type<span class=\"ansi-blue-fg\">(</span>row<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1066</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1067</span>     fields <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">[</span><span class=\"ansi-blue-fg\">]</span>\n\n<span class=\"ansi-red-fg\">TypeError</span>: Can not infer schema for type: &lt;class &#39;str&#39;&gt;</div>", "errorSummary": "<span class=\"ansi-red-fg\">TypeError</span>: Can not infer schema for type: &lt;class &#39;str&#39;&gt;", "metadata": {}, "errorTraceType": "html", "type": "ipynbError", "arguments": {}}}, "data": {"text/html": ["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">TypeError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-2168700272281627&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span>spark<span class=\"ansi-blue-fg\">.</span>createDataFrame<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">{</span><span class=\"ansi-blue-fg\">&#34;season&#34;</span><span class=\"ansi-blue-fg\">:</span> <span class=\"ansi-blue-fg\">[</span><span class=\"ansi-blue-fg\">&#34;winter&#34;</span><span class=\"ansi-blue-fg\">,</span><span class=\"ansi-blue-fg\">&#34;summer&#34;</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;wind_speed_ms&#34;</span><span class=\"ansi-blue-fg\">:</span> <span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">4.5</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">7.5</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">}</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>show<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">createDataFrame</span><span class=\"ansi-blue-fg\">(self, data, schema, samplingRatio, verifySchema)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    720</span>             return super(SparkSession, self).createDataFrame(\n<span class=\"ansi-green-intense-fg ansi-bold\">    721</span>                 data, schema, samplingRatio, verifySchema)\n<span class=\"ansi-green-fg\">--&gt; 722</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_create_dataframe<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">,</span> samplingRatio<span class=\"ansi-blue-fg\">,</span> verifySchema<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    723</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    724</span>     <span class=\"ansi-green-fg\">def</span> _create_dataframe<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> data<span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">,</span> samplingRatio<span class=\"ansi-blue-fg\">,</span> verifySchema<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">_create_dataframe</span><span class=\"ansi-blue-fg\">(self, data, schema, samplingRatio, verifySchema)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    752</span>                 rdd<span class=\"ansi-blue-fg\">,</span> schema <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_createFromRDD<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">.</span>map<span class=\"ansi-blue-fg\">(</span>prepare<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">,</span> samplingRatio<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    753</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 754</span><span class=\"ansi-red-fg\">                 </span>rdd<span class=\"ansi-blue-fg\">,</span> schema <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_createFromLocal<span class=\"ansi-blue-fg\">(</span>map<span class=\"ansi-blue-fg\">(</span>prepare<span class=\"ansi-blue-fg\">,</span> data<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    755</span>             jrdd <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_jvm<span class=\"ansi-blue-fg\">.</span>SerDeUtil<span class=\"ansi-blue-fg\">.</span>toJavaArray<span class=\"ansi-blue-fg\">(</span>rdd<span class=\"ansi-blue-fg\">.</span>_to_java_object_rdd<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    756</span>             jdf <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_jsparkSession<span class=\"ansi-blue-fg\">.</span>applySchemaToPythonRDD<span class=\"ansi-blue-fg\">(</span>jrdd<span class=\"ansi-blue-fg\">.</span>rdd<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">.</span>json<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">_createFromLocal</span><span class=\"ansi-blue-fg\">(self, data, schema)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    528</span>         write temp files<span class=\"ansi-blue-fg\">.</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    529</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-fg\">--&gt; 530</span><span class=\"ansi-red-fg\">         </span>data<span class=\"ansi-blue-fg\">,</span> schema <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_wrap_data_schema<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">,</span> schema<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    531</span>         <span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_sc<span class=\"ansi-blue-fg\">.</span>parallelize<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> schema\n<span class=\"ansi-green-intense-fg ansi-bold\">    532</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">_wrap_data_schema</span><span class=\"ansi-blue-fg\">(self, data, schema)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    507</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    508</span>         <span class=\"ansi-green-fg\">if</span> schema <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">None</span> <span class=\"ansi-green-fg\">or</span> isinstance<span class=\"ansi-blue-fg\">(</span>schema<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">(</span>list<span class=\"ansi-blue-fg\">,</span> tuple<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 509</span><span class=\"ansi-red-fg\">             </span>struct <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_inferSchemaFromList<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">,</span> names<span class=\"ansi-blue-fg\">=</span>schema<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    510</span>             converter <span class=\"ansi-blue-fg\">=</span> _create_converter<span class=\"ansi-blue-fg\">(</span>struct<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    511</span>             data <span class=\"ansi-blue-fg\">=</span> map<span class=\"ansi-blue-fg\">(</span>converter<span class=\"ansi-blue-fg\">,</span> data<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">_inferSchemaFromList</span><span class=\"ansi-blue-fg\">(self, data, names)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    438</span>         <span class=\"ansi-green-fg\">if</span> <span class=\"ansi-green-fg\">not</span> data<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    439</span>             <span class=\"ansi-green-fg\">raise</span> ValueError<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;can not infer schema from empty dataset&#34;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">--&gt; 440</span><span class=\"ansi-red-fg\">         </span>schema <span class=\"ansi-blue-fg\">=</span> reduce<span class=\"ansi-blue-fg\">(</span>_merge_type<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">(</span>_infer_schema<span class=\"ansi-blue-fg\">(</span>row<span class=\"ansi-blue-fg\">,</span> names<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">for</span> row <span class=\"ansi-green-fg\">in</span> data<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    441</span>         <span class=\"ansi-green-fg\">if</span> _has_nulltype<span class=\"ansi-blue-fg\">(</span>schema<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    442</span>             <span class=\"ansi-green-fg\">raise</span> ValueError<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;Some of types cannot be determined after inferring&#34;</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">&lt;genexpr&gt;</span><span class=\"ansi-blue-fg\">(.0)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    438</span>         <span class=\"ansi-green-fg\">if</span> <span class=\"ansi-green-fg\">not</span> data<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    439</span>             <span class=\"ansi-green-fg\">raise</span> ValueError<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;can not infer schema from empty dataset&#34;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">--&gt; 440</span><span class=\"ansi-red-fg\">         </span>schema <span class=\"ansi-blue-fg\">=</span> reduce<span class=\"ansi-blue-fg\">(</span>_merge_type<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">(</span>_infer_schema<span class=\"ansi-blue-fg\">(</span>row<span class=\"ansi-blue-fg\">,</span> names<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">for</span> row <span class=\"ansi-green-fg\">in</span> data<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    441</span>         <span class=\"ansi-green-fg\">if</span> _has_nulltype<span class=\"ansi-blue-fg\">(</span>schema<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    442</span>             <span class=\"ansi-green-fg\">raise</span> ValueError<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;Some of types cannot be determined after inferring&#34;</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/types.py</span> in <span class=\"ansi-cyan-fg\">_infer_schema</span><span class=\"ansi-blue-fg\">(row, names)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1063</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1064</span>     <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">-&gt; 1065</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">raise</span> TypeError<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;Can not infer schema for type: %s&#34;</span> <span class=\"ansi-blue-fg\">%</span> type<span class=\"ansi-blue-fg\">(</span>row<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1066</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1067</span>     fields <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">[</span><span class=\"ansi-blue-fg\">]</span>\n\n<span class=\"ansi-red-fg\">TypeError</span>: Can not infer schema for type: &lt;class &#39;str&#39;&gt;</div>"]}}], "execution_count": 0}], "metadata": {"application/vnd.databricks.v1+notebook": {"notebookName": "58", "dashboards": [], "notebookMetadata": {"pythonIndentUnit": 2}, "language": "python", "widgets": {}, "notebookOrigID": 2168700272281617}}, "nbformat": 4, "nbformat_minor": 0}